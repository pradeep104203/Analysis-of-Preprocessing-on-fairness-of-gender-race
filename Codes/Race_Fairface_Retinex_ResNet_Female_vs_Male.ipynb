{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Race_Fairface Retinex ResNet - Female vs Male.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70ba3b19c59d43b7a883be2ab433275e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_638e1393d4a54789a59a9ed53ef0331f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e5731c8712e5464e90a8257332eb360c",
              "IPY_MODEL_b2e331ca981349a68323c203ad7e2724"
            ]
          }
        },
        "638e1393d4a54789a59a9ed53ef0331f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5731c8712e5464e90a8257332eb360c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_464a6c8ca9944b34ad190459d917c6c5",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3b0fc89dfc548baac5eab26516098da"
          }
        },
        "b2e331ca981349a68323c203ad7e2724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1cfcd7b380cf403dbc59a53382b81e96",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [23:12:47&lt;00:00, 560B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6306229c7881476f8a005431f6efccc6"
          }
        },
        "464a6c8ca9944b34ad190459d917c6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3b0fc89dfc548baac5eab26516098da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cfcd7b380cf403dbc59a53382b81e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6306229c7881476f8a005431f6efccc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "svuc-ltEpS9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c842b45-cb7e-4762-a123-f86653b4d156"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibeC5clW-2b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15912ea0-b215-46b4-c78f-d5014e878c2d"
      },
      "source": [
        "!fairfaceequ ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: fairfaceequ: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZzoOX_Jp_SU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1ebcd0-248c-4cdd-fe4f-ff71faf16006"
      },
      "source": [
        "cd drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fy44Qtsp6ME"
      },
      "source": [
        "!unzip fairfaceretinex.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ejo4DfHpvhQ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import time\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qznHrjspOpg"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26sTQN0OpOpj"
      },
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                           transforms.RandomHorizontalFlip(),\n",
        "                           transforms.RandomRotation(10),\n",
        "                           transforms.RandomCrop((224, 224), pad_if_needed=True),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
        "                       ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                           transforms.CenterCrop((224, 224)),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
        "                       ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03NG8Ng1pOpm"
      },
      "source": [
        "train_data = datasets.ImageFolder('fairfaceretinex/Training', train_transforms)\n",
        "valid_data = datasets.ImageFolder('fairfaceretinex/Validation', test_transforms)\n",
        "#test_data = datasets.ImageFolder('fairfaceequ/Validation/Male/1.jpg', test_transforms)\n",
        "\n",
        "#import os\n",
        "\n",
        "#print(len(os.listdir('data/dogs-vs-cats/train')))\n",
        "\n",
        "#n_train_examples = int(len(train_data)*0.9)\n",
        "#n_valid_examples = n_test_examples = len(train_data) - n_train_examples\n",
        "\n",
        "#train_data, valid_data = torch.utils.data.random_split(train_data, [n_train_examples, n_valid_examples])\n",
        "#train_data, test_data = torch.utils.data.random_split(train_data, [n_train_examples-n_valid_examples, n_test_examples])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQfK_O0cpOpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa328da-2636-4a60-cbc8-0f73470d03f5"
      },
      "source": [
        "print(valid_data.class_to_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Female': 0, 'Male': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yyshQspOpu"
      },
      "source": [
        "https://github.com/facebook/fb.resnet.torch/issues/180\n",
        "https://github.com/bamos/densenet.pytorch/blob/master/compute-cifar10-mean.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J36So8hBpOpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca35943c-44b4-4812-9898-1453fdceeabd"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "#print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 85902\n",
            "Number of validation examples: 10836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8W-L_FxpOpx"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
        "valid_iterator = torch.utils.data.DataLoader(valid_data, batch_size=BATCH_SIZE)\n",
        "#test_iterator = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LKm33q8pOp1"
      },
      "source": [
        "https://discuss.pytorch.org/t/why-does-the-resnet-model-given-by-pytorch-omit-biases-from-the-convolutional-layer/10990/4\n",
        "https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMKyjQN1pOp1"
      },
      "source": [
        "device = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILbjh2OppOp4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "70ba3b19c59d43b7a883be2ab433275e",
            "638e1393d4a54789a59a9ed53ef0331f",
            "e5731c8712e5464e90a8257332eb360c",
            "b2e331ca981349a68323c203ad7e2724",
            "464a6c8ca9944b34ad190459d917c6c5",
            "b3b0fc89dfc548baac5eab26516098da",
            "1cfcd7b380cf403dbc59a53382b81e96",
            "6306229c7881476f8a005431f6efccc6"
          ]
        },
        "outputId": "276858e0-370f-4af3-aca9-951f5dcef17f"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "model = models.resnet18(pretrained=True).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70ba3b19c59d43b7a883be2ab433275e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQxfOCrDpOp9"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VJdtyyrpOp_"
      },
      "source": [
        "from torch.optim import lr_scheduler\n",
        "\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(512, 2)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6DhUhryx8NV"
      },
      "source": [
        "Adam optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoYGo0lYx__c"
      },
      "source": [
        "from torch.optim import lr_scheduler\n",
        "\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(512, 2)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999),eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15zKBiwzpOqB"
      },
      "source": [
        "def calculate_accuracy(fx, y):\n",
        "    preds = fx.max(1, keepdim=True)[1]\n",
        "    correct = preds.eq(y.view_as(preds)).sum()\n",
        "    acc = correct.float()/preds.shape[0]\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XX-7__TpOqE"
      },
      "source": [
        "def train(model, device, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for (x, y) in iterator:\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        fx = model(x)\n",
        "        \n",
        "        loss = criterion(fx, y)\n",
        "        \n",
        "        acc = calculate_accuracy(fx, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukCZYJSGpOqH"
      },
      "source": [
        "def evaluate(model, device, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            fx = model(x)\n",
        "\n",
        "            loss = criterion(fx, y)\n",
        "\n",
        "            acc = calculate_accuracy(fx, y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiqnQl-fNbbZ"
      },
      "source": [
        "old model without history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqU4An9lpOqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15e7f41-3cec-4075-be66-d1fd25ef6b30"
      },
      "source": [
        "EPOCHS = 60\n",
        "SAVE_DIR = 'models'\n",
        "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'RaceMultiscaleretinex-ResentFT-males-vs-females.pt')\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "if not os.path.isdir(f'{SAVE_DIR}'):\n",
        "    os.makedirs(f'{SAVE_DIR}')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train(model, device, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, device, valid_iterator, criterion)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "    \n",
        "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:05.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:05.2f}% |')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.578 | Train Acc: 68.48% | Val. Loss: 0.512 | Val. Acc: 73.78% |\n",
            "| Epoch: 02 | Train Loss: 0.500 | Train Acc: 74.05% | Val. Loss: 0.441 | Val. Acc: 78.10% |\n",
            "| Epoch: 03 | Train Loss: 0.471 | Train Acc: 75.90% | Val. Loss: 0.413 | Val. Acc: 79.58% |\n",
            "| Epoch: 04 | Train Loss: 0.455 | Train Acc: 76.98% | Val. Loss: 0.396 | Val. Acc: 80.34% |\n",
            "| Epoch: 05 | Train Loss: 0.442 | Train Acc: 77.81% | Val. Loss: 0.379 | Val. Acc: 81.55% |\n",
            "| Epoch: 06 | Train Loss: 0.433 | Train Acc: 78.28% | Val. Loss: 0.385 | Val. Acc: 81.26% |\n",
            "| Epoch: 07 | Train Loss: 0.425 | Train Acc: 79.02% | Val. Loss: 0.396 | Val. Acc: 80.33% |\n",
            "| Epoch: 08 | Train Loss: 0.418 | Train Acc: 79.31% | Val. Loss: 0.363 | Val. Acc: 82.32% |\n",
            "| Epoch: 09 | Train Loss: 0.413 | Train Acc: 79.51% | Val. Loss: 0.354 | Val. Acc: 82.78% |\n",
            "| Epoch: 10 | Train Loss: 0.405 | Train Acc: 80.15% | Val. Loss: 0.348 | Val. Acc: 83.58% |\n",
            "| Epoch: 11 | Train Loss: 0.403 | Train Acc: 80.08% | Val. Loss: 0.366 | Val. Acc: 82.26% |\n",
            "| Epoch: 12 | Train Loss: 0.399 | Train Acc: 80.26% | Val. Loss: 0.342 | Val. Acc: 83.55% |\n",
            "| Epoch: 13 | Train Loss: 0.392 | Train Acc: 80.89% | Val. Loss: 0.337 | Val. Acc: 83.92% |\n",
            "| Epoch: 14 | Train Loss: 0.387 | Train Acc: 80.95% | Val. Loss: 0.343 | Val. Acc: 83.40% |\n",
            "| Epoch: 15 | Train Loss: 0.385 | Train Acc: 81.29% | Val. Loss: 0.353 | Val. Acc: 83.02% |\n",
            "| Epoch: 16 | Train Loss: 0.381 | Train Acc: 81.59% | Val. Loss: 0.350 | Val. Acc: 83.56% |\n",
            "| Epoch: 17 | Train Loss: 0.379 | Train Acc: 81.63% | Val. Loss: 0.333 | Val. Acc: 84.05% |\n",
            "| Epoch: 18 | Train Loss: 0.375 | Train Acc: 81.82% | Val. Loss: 0.335 | Val. Acc: 84.75% |\n",
            "| Epoch: 19 | Train Loss: 0.369 | Train Acc: 81.99% | Val. Loss: 0.334 | Val. Acc: 84.07% |\n",
            "| Epoch: 20 | Train Loss: 0.369 | Train Acc: 82.17% | Val. Loss: 0.363 | Val. Acc: 82.69% |\n",
            "| Epoch: 21 | Train Loss: 0.365 | Train Acc: 82.43% | Val. Loss: 0.323 | Val. Acc: 84.74% |\n",
            "| Epoch: 22 | Train Loss: 0.366 | Train Acc: 82.22% | Val. Loss: 0.328 | Val. Acc: 84.79% |\n",
            "| Epoch: 23 | Train Loss: 0.361 | Train Acc: 82.58% | Val. Loss: 0.350 | Val. Acc: 83.93% |\n",
            "| Epoch: 24 | Train Loss: 0.358 | Train Acc: 82.76% | Val. Loss: 0.318 | Val. Acc: 84.90% |\n",
            "| Epoch: 25 | Train Loss: 0.356 | Train Acc: 82.82% | Val. Loss: 0.340 | Val. Acc: 84.62% |\n",
            "| Epoch: 26 | Train Loss: 0.353 | Train Acc: 83.02% | Val. Loss: 0.316 | Val. Acc: 85.34% |\n",
            "| Epoch: 27 | Train Loss: 0.352 | Train Acc: 83.18% | Val. Loss: 0.337 | Val. Acc: 84.29% |\n",
            "| Epoch: 28 | Train Loss: 0.353 | Train Acc: 82.93% | Val. Loss: 0.325 | Val. Acc: 85.16% |\n",
            "| Epoch: 29 | Train Loss: 0.347 | Train Acc: 83.46% | Val. Loss: 0.327 | Val. Acc: 84.99% |\n",
            "| Epoch: 30 | Train Loss: 0.344 | Train Acc: 83.62% | Val. Loss: 0.320 | Val. Acc: 84.97% |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvUHRdxSvs_D"
      },
      "source": [
        "Adam epoch increment model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXHSzp7MNguy"
      },
      "source": [
        "epoch increment history model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gI_ShigNE-C",
        "outputId": "524706fa-4daf-4cab-fbcb-78765962874d"
      },
      "source": [
        "EPOCHS = 60\n",
        "SAVE_DIR = 'models'\n",
        "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'ColabRaceresnet-ResentFT-males-vs-females.pt')\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "if not os.path.isdir(f'{SAVE_DIR}'):\n",
        "    os.makedirs(f'{SAVE_DIR}')\n",
        "history = []\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_start = time.time()\n",
        "    train_loss, train_acc = train(model, device, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, device, valid_iterator, criterion)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "\n",
        "    history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
        "    epoch_end = time.time()\n",
        "    \n",
        "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:05.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:05.2f}% | Time: {epoch_end-epoch_start:.4f}s |')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.573 | Train Acc: 68.73% | Val. Loss: 0.532 | Val. Acc: 72.60% | Time: 946.2113s |\n",
            "| Epoch: 02 | Train Loss: 0.498 | Train Acc: 74.32% | Val. Loss: 0.428 | Val. Acc: 78.78% | Time: 910.7252s |\n",
            "| Epoch: 03 | Train Loss: 0.469 | Train Acc: 76.22% | Val. Loss: 0.404 | Val. Acc: 80.06% | Time: 900.1948s |\n",
            "| Epoch: 04 | Train Loss: 0.455 | Train Acc: 76.83% | Val. Loss: 0.407 | Val. Acc: 80.38% | Time: 892.6625s |\n",
            "| Epoch: 05 | Train Loss: 0.442 | Train Acc: 77.81% | Val. Loss: 0.388 | Val. Acc: 81.05% | Time: 882.2377s |\n",
            "| Epoch: 06 | Train Loss: 0.435 | Train Acc: 78.39% | Val. Loss: 0.439 | Val. Acc: 78.77% | Time: 869.0003s |\n",
            "| Epoch: 07 | Train Loss: 0.425 | Train Acc: 78.89% | Val. Loss: 0.363 | Val. Acc: 82.69% | Time: 859.3664s |\n",
            "| Epoch: 08 | Train Loss: 0.418 | Train Acc: 79.46% | Val. Loss: 0.362 | Val. Acc: 82.27% | Time: 859.3354s |\n",
            "| Epoch: 09 | Train Loss: 0.410 | Train Acc: 79.63% | Val. Loss: 0.373 | Val. Acc: 82.12% | Time: 899.7110s |\n",
            "| Epoch: 10 | Train Loss: 0.405 | Train Acc: 79.96% | Val. Loss: 0.365 | Val. Acc: 82.42% | Time: 855.3705s |\n",
            "| Epoch: 11 | Train Loss: 0.399 | Train Acc: 80.38% | Val. Loss: 0.379 | Val. Acc: 82.23% | Time: 873.3233s |\n",
            "| Epoch: 12 | Train Loss: 0.396 | Train Acc: 80.53% | Val. Loss: 0.400 | Val. Acc: 81.12% | Time: 894.8006s |\n",
            "| Epoch: 13 | Train Loss: 0.392 | Train Acc: 80.85% | Val. Loss: 0.375 | Val. Acc: 82.19% | Time: 909.3385s |\n",
            "| Epoch: 14 | Train Loss: 0.387 | Train Acc: 81.13% | Val. Loss: 0.362 | Val. Acc: 82.66% | Time: 897.6627s |\n",
            "| Epoch: 15 | Train Loss: 0.383 | Train Acc: 81.35% | Val. Loss: 0.340 | Val. Acc: 83.82% | Time: 875.7112s |\n",
            "| Epoch: 16 | Train Loss: 0.379 | Train Acc: 81.57% | Val. Loss: 0.352 | Val. Acc: 83.10% | Time: 871.4017s |\n",
            "| Epoch: 17 | Train Loss: 0.378 | Train Acc: 81.47% | Val. Loss: 0.399 | Val. Acc: 81.85% | Time: 904.5295s |\n",
            "| Epoch: 18 | Train Loss: 0.376 | Train Acc: 81.76% | Val. Loss: 0.339 | Val. Acc: 83.67% | Time: 898.8586s |\n",
            "| Epoch: 19 | Train Loss: 0.371 | Train Acc: 82.04% | Val. Loss: 0.339 | Val. Acc: 83.86% | Time: 903.9639s |\n",
            "| Epoch: 20 | Train Loss: 0.368 | Train Acc: 82.19% | Val. Loss: 0.332 | Val. Acc: 84.12% | Time: 925.9437s |\n",
            "| Epoch: 21 | Train Loss: 0.364 | Train Acc: 82.35% | Val. Loss: 0.397 | Val. Acc: 82.23% | Time: 912.3087s |\n",
            "| Epoch: 22 | Train Loss: 0.365 | Train Acc: 82.38% | Val. Loss: 0.382 | Val. Acc: 82.03% | Time: 904.4006s |\n",
            "| Epoch: 23 | Train Loss: 0.362 | Train Acc: 82.50% | Val. Loss: 0.352 | Val. Acc: 83.31% | Time: 902.4858s |\n",
            "| Epoch: 24 | Train Loss: 0.360 | Train Acc: 82.73% | Val. Loss: 0.333 | Val. Acc: 84.73% | Time: 887.8164s |\n",
            "| Epoch: 25 | Train Loss: 0.358 | Train Acc: 82.65% | Val. Loss: 0.332 | Val. Acc: 84.66% | Time: 872.4406s |\n",
            "| Epoch: 26 | Train Loss: 0.355 | Train Acc: 82.83% | Val. Loss: 0.333 | Val. Acc: 84.90% | Time: 872.7026s |\n",
            "| Epoch: 27 | Train Loss: 0.350 | Train Acc: 83.26% | Val. Loss: 0.338 | Val. Acc: 84.33% | Time: 865.8730s |\n",
            "| Epoch: 28 | Train Loss: 0.350 | Train Acc: 83.23% | Val. Loss: 0.318 | Val. Acc: 85.10% | Time: 874.9879s |\n",
            "| Epoch: 29 | Train Loss: 0.350 | Train Acc: 83.24% | Val. Loss: 0.315 | Val. Acc: 85.48% | Time: 890.7818s |\n",
            "| Epoch: 30 | Train Loss: 0.346 | Train Acc: 83.24% | Val. Loss: 0.340 | Val. Acc: 84.39% | Time: 892.1204s |\n",
            "| Epoch: 31 | Train Loss: 0.344 | Train Acc: 83.46% | Val. Loss: 0.334 | Val. Acc: 85.15% | Time: 879.1619s |\n",
            "| Epoch: 32 | Train Loss: 0.341 | Train Acc: 83.70% | Val. Loss: 0.315 | Val. Acc: 85.37% | Time: 870.3271s |\n",
            "| Epoch: 33 | Train Loss: 0.340 | Train Acc: 83.76% | Val. Loss: 0.342 | Val. Acc: 84.29% | Time: 861.3748s |\n",
            "| Epoch: 34 | Train Loss: 0.339 | Train Acc: 83.81% | Val. Loss: 0.317 | Val. Acc: 85.56% | Time: 861.5202s |\n",
            "| Epoch: 35 | Train Loss: 0.338 | Train Acc: 83.95% | Val. Loss: 0.322 | Val. Acc: 84.99% | Time: 863.2852s |\n",
            "| Epoch: 36 | Train Loss: 0.332 | Train Acc: 84.29% | Val. Loss: 0.319 | Val. Acc: 85.24% | Time: 852.1326s |\n",
            "| Epoch: 37 | Train Loss: 0.333 | Train Acc: 84.08% | Val. Loss: 0.338 | Val. Acc: 85.16% | Time: 850.0898s |\n",
            "| Epoch: 38 | Train Loss: 0.331 | Train Acc: 84.19% | Val. Loss: 0.335 | Val. Acc: 84.86% | Time: 858.7350s |\n",
            "| Epoch: 39 | Train Loss: 0.331 | Train Acc: 84.35% | Val. Loss: 0.323 | Val. Acc: 85.59% | Time: 849.7158s |\n",
            "| Epoch: 40 | Train Loss: 0.327 | Train Acc: 84.48% | Val. Loss: 0.330 | Val. Acc: 85.61% | Time: 882.4269s |\n",
            "| Epoch: 41 | Train Loss: 0.327 | Train Acc: 84.46% | Val. Loss: 0.314 | Val. Acc: 85.89% | Time: 909.4637s |\n",
            "| Epoch: 42 | Train Loss: 0.324 | Train Acc: 84.57% | Val. Loss: 0.338 | Val. Acc: 85.70% | Time: 908.6595s |\n",
            "| Epoch: 43 | Train Loss: 0.322 | Train Acc: 84.73% | Val. Loss: 0.315 | Val. Acc: 85.51% | Time: 905.0508s |\n",
            "| Epoch: 44 | Train Loss: 0.322 | Train Acc: 84.73% | Val. Loss: 0.322 | Val. Acc: 85.32% | Time: 905.0049s |\n",
            "| Epoch: 45 | Train Loss: 0.319 | Train Acc: 84.92% | Val. Loss: 0.323 | Val. Acc: 85.12% | Time: 917.0500s |\n",
            "| Epoch: 46 | Train Loss: 0.319 | Train Acc: 84.86% | Val. Loss: 0.342 | Val. Acc: 85.38% | Time: 916.7134s |\n",
            "| Epoch: 47 | Train Loss: 0.317 | Train Acc: 85.01% | Val. Loss: 0.320 | Val. Acc: 85.84% | Time: 876.9990s |\n",
            "| Epoch: 48 | Train Loss: 0.314 | Train Acc: 85.14% | Val. Loss: 0.360 | Val. Acc: 85.15% | Time: 890.9197s |\n",
            "| Epoch: 49 | Train Loss: 0.315 | Train Acc: 85.16% | Val. Loss: 0.326 | Val. Acc: 85.50% | Time: 888.3504s |\n",
            "| Epoch: 50 | Train Loss: 0.312 | Train Acc: 85.27% | Val. Loss: 0.317 | Val. Acc: 85.44% | Time: 849.0002s |\n",
            "| Epoch: 51 | Train Loss: 0.311 | Train Acc: 85.24% | Val. Loss: 0.339 | Val. Acc: 85.29% | Time: 851.0881s |\n",
            "| Epoch: 52 | Train Loss: 0.310 | Train Acc: 85.39% | Val. Loss: 0.328 | Val. Acc: 85.42% | Time: 898.4569s |\n",
            "| Epoch: 53 | Train Loss: 0.306 | Train Acc: 85.57% | Val. Loss: 0.329 | Val. Acc: 85.54% | Time: 868.6745s |\n",
            "| Epoch: 54 | Train Loss: 0.306 | Train Acc: 85.65% | Val. Loss: 0.324 | Val. Acc: 85.38% | Time: 824.6315s |\n",
            "| Epoch: 55 | Train Loss: 0.304 | Train Acc: 85.85% | Val. Loss: 0.333 | Val. Acc: 85.58% | Time: 839.4730s |\n",
            "| Epoch: 56 | Train Loss: 0.304 | Train Acc: 85.61% | Val. Loss: 0.326 | Val. Acc: 85.85% | Time: 841.5515s |\n",
            "| Epoch: 57 | Train Loss: 0.303 | Train Acc: 85.70% | Val. Loss: 0.325 | Val. Acc: 85.52% | Time: 853.9231s |\n",
            "| Epoch: 58 | Train Loss: 0.300 | Train Acc: 85.92% | Val. Loss: 0.337 | Val. Acc: 85.15% | Time: 857.0634s |\n",
            "| Epoch: 59 | Train Loss: 0.298 | Train Acc: 86.11% | Val. Loss: 0.338 | Val. Acc: 85.43% | Time: 844.5402s |\n",
            "| Epoch: 60 | Train Loss: 0.297 | Train Acc: 86.15% | Val. Loss: 0.337 | Val. Acc: 85.15% | Time: 869.9521s |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGlrruzBU8n_",
        "outputId": "c3b5f348-7591-402c-9210-9295981acac3"
      },
      "source": [
        "EPOCHS = 100\n",
        "SAVE_DIR = 'models'\n",
        "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'ClbRaceresnet-ResentFT-males-vs-females.pt')\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "if not os.path.isdir(f'{SAVE_DIR}'):\n",
        "    os.makedirs(f'{SAVE_DIR}')\n",
        "history = []\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_start = time.time()\n",
        "    train_loss, train_acc = train(model, device, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, device, valid_iterator, criterion)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "\n",
        "    history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
        "    epoch_end = time.time()\n",
        "    \n",
        "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:05.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:05.2f}% | Time: {epoch_end-epoch_start:.4f}s |')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.573 | Train Acc: 68.73% | Val. Loss: 0.532 | Val. Acc: 72.60% | Time: 905.4446s |\n",
            "| Epoch: 02 | Train Loss: 0.498 | Train Acc: 74.32% | Val. Loss: 0.428 | Val. Acc: 78.78% | Time: 885.2020s |\n",
            "| Epoch: 03 | Train Loss: 0.469 | Train Acc: 76.22% | Val. Loss: 0.404 | Val. Acc: 80.06% | Time: 868.2649s |\n",
            "| Epoch: 04 | Train Loss: 0.455 | Train Acc: 76.83% | Val. Loss: 0.407 | Val. Acc: 80.38% | Time: 895.0608s |\n",
            "| Epoch: 05 | Train Loss: 0.442 | Train Acc: 77.81% | Val. Loss: 0.388 | Val. Acc: 81.05% | Time: 871.4615s |\n",
            "| Epoch: 06 | Train Loss: 0.435 | Train Acc: 78.39% | Val. Loss: 0.439 | Val. Acc: 78.77% | Time: 837.8308s |\n",
            "| Epoch: 07 | Train Loss: 0.425 | Train Acc: 78.89% | Val. Loss: 0.363 | Val. Acc: 82.69% | Time: 839.9215s |\n",
            "| Epoch: 08 | Train Loss: 0.418 | Train Acc: 79.46% | Val. Loss: 0.362 | Val. Acc: 82.27% | Time: 859.4010s |\n",
            "| Epoch: 09 | Train Loss: 0.410 | Train Acc: 79.63% | Val. Loss: 0.373 | Val. Acc: 82.12% | Time: 835.1146s |\n",
            "| Epoch: 10 | Train Loss: 0.405 | Train Acc: 79.96% | Val. Loss: 0.365 | Val. Acc: 82.42% | Time: 813.6030s |\n",
            "| Epoch: 11 | Train Loss: 0.399 | Train Acc: 80.38% | Val. Loss: 0.379 | Val. Acc: 82.23% | Time: 818.0148s |\n",
            "| Epoch: 12 | Train Loss: 0.396 | Train Acc: 80.53% | Val. Loss: 0.400 | Val. Acc: 81.12% | Time: 804.5724s |\n",
            "| Epoch: 13 | Train Loss: 0.392 | Train Acc: 80.85% | Val. Loss: 0.375 | Val. Acc: 82.19% | Time: 789.6516s |\n",
            "| Epoch: 14 | Train Loss: 0.387 | Train Acc: 81.13% | Val. Loss: 0.362 | Val. Acc: 82.66% | Time: 784.4377s |\n",
            "| Epoch: 15 | Train Loss: 0.383 | Train Acc: 81.35% | Val. Loss: 0.340 | Val. Acc: 83.82% | Time: 837.1351s |\n",
            "| Epoch: 16 | Train Loss: 0.379 | Train Acc: 81.57% | Val. Loss: 0.352 | Val. Acc: 83.10% | Time: 838.5769s |\n",
            "| Epoch: 17 | Train Loss: 0.378 | Train Acc: 81.47% | Val. Loss: 0.399 | Val. Acc: 81.85% | Time: 820.2856s |\n",
            "| Epoch: 18 | Train Loss: 0.376 | Train Acc: 81.76% | Val. Loss: 0.339 | Val. Acc: 83.67% | Time: 804.5150s |\n",
            "| Epoch: 19 | Train Loss: 0.371 | Train Acc: 82.04% | Val. Loss: 0.339 | Val. Acc: 83.86% | Time: 799.9849s |\n",
            "| Epoch: 20 | Train Loss: 0.368 | Train Acc: 82.19% | Val. Loss: 0.332 | Val. Acc: 84.12% | Time: 830.6787s |\n",
            "| Epoch: 21 | Train Loss: 0.364 | Train Acc: 82.35% | Val. Loss: 0.397 | Val. Acc: 82.23% | Time: 810.2297s |\n",
            "| Epoch: 22 | Train Loss: 0.365 | Train Acc: 82.38% | Val. Loss: 0.382 | Val. Acc: 82.03% | Time: 816.1431s |\n",
            "| Epoch: 23 | Train Loss: 0.362 | Train Acc: 82.50% | Val. Loss: 0.352 | Val. Acc: 83.31% | Time: 882.3419s |\n",
            "| Epoch: 24 | Train Loss: 0.360 | Train Acc: 82.73% | Val. Loss: 0.333 | Val. Acc: 84.73% | Time: 845.6114s |\n",
            "| Epoch: 25 | Train Loss: 0.358 | Train Acc: 82.65% | Val. Loss: 0.332 | Val. Acc: 84.66% | Time: 812.9979s |\n",
            "| Epoch: 26 | Train Loss: 0.355 | Train Acc: 82.83% | Val. Loss: 0.333 | Val. Acc: 84.90% | Time: 831.8188s |\n",
            "| Epoch: 27 | Train Loss: 0.350 | Train Acc: 83.26% | Val. Loss: 0.338 | Val. Acc: 84.33% | Time: 838.7663s |\n",
            "| Epoch: 28 | Train Loss: 0.350 | Train Acc: 83.23% | Val. Loss: 0.318 | Val. Acc: 85.10% | Time: 844.4193s |\n",
            "| Epoch: 29 | Train Loss: 0.350 | Train Acc: 83.24% | Val. Loss: 0.315 | Val. Acc: 85.48% | Time: 848.3930s |\n",
            "| Epoch: 30 | Train Loss: 0.346 | Train Acc: 83.24% | Val. Loss: 0.340 | Val. Acc: 84.39% | Time: 826.9365s |\n",
            "| Epoch: 31 | Train Loss: 0.344 | Train Acc: 83.46% | Val. Loss: 0.334 | Val. Acc: 85.15% | Time: 779.3449s |\n",
            "| Epoch: 32 | Train Loss: 0.341 | Train Acc: 83.70% | Val. Loss: 0.315 | Val. Acc: 85.37% | Time: 786.1009s |\n",
            "| Epoch: 33 | Train Loss: 0.340 | Train Acc: 83.76% | Val. Loss: 0.342 | Val. Acc: 84.29% | Time: 780.8795s |\n",
            "| Epoch: 34 | Train Loss: 0.339 | Train Acc: 83.81% | Val. Loss: 0.317 | Val. Acc: 85.56% | Time: 819.8320s |\n",
            "| Epoch: 35 | Train Loss: 0.338 | Train Acc: 83.95% | Val. Loss: 0.322 | Val. Acc: 84.99% | Time: 817.9748s |\n",
            "| Epoch: 36 | Train Loss: 0.332 | Train Acc: 84.29% | Val. Loss: 0.319 | Val. Acc: 85.24% | Time: 857.5207s |\n",
            "| Epoch: 37 | Train Loss: 0.333 | Train Acc: 84.08% | Val. Loss: 0.338 | Val. Acc: 85.16% | Time: 819.8090s |\n",
            "| Epoch: 38 | Train Loss: 0.331 | Train Acc: 84.19% | Val. Loss: 0.335 | Val. Acc: 84.86% | Time: 851.8049s |\n",
            "| Epoch: 39 | Train Loss: 0.331 | Train Acc: 84.35% | Val. Loss: 0.323 | Val. Acc: 85.59% | Time: 804.3180s |\n",
            "| Epoch: 40 | Train Loss: 0.327 | Train Acc: 84.48% | Val. Loss: 0.330 | Val. Acc: 85.61% | Time: 771.2257s |\n",
            "| Epoch: 41 | Train Loss: 0.327 | Train Acc: 84.46% | Val. Loss: 0.314 | Val. Acc: 85.89% | Time: 812.1777s |\n",
            "| Epoch: 42 | Train Loss: 0.324 | Train Acc: 84.57% | Val. Loss: 0.338 | Val. Acc: 85.70% | Time: 861.0187s |\n",
            "| Epoch: 43 | Train Loss: 0.322 | Train Acc: 84.73% | Val. Loss: 0.315 | Val. Acc: 85.51% | Time: 867.9093s |\n",
            "| Epoch: 44 | Train Loss: 0.322 | Train Acc: 84.73% | Val. Loss: 0.322 | Val. Acc: 85.32% | Time: 866.8825s |\n",
            "| Epoch: 45 | Train Loss: 0.319 | Train Acc: 84.92% | Val. Loss: 0.323 | Val. Acc: 85.12% | Time: 793.8444s |\n",
            "| Epoch: 46 | Train Loss: 0.319 | Train Acc: 84.86% | Val. Loss: 0.342 | Val. Acc: 85.38% | Time: 779.3228s |\n",
            "| Epoch: 47 | Train Loss: 0.317 | Train Acc: 85.01% | Val. Loss: 0.320 | Val. Acc: 85.84% | Time: 784.1268s |\n",
            "| Epoch: 48 | Train Loss: 0.314 | Train Acc: 85.14% | Val. Loss: 0.360 | Val. Acc: 85.15% | Time: 790.5796s |\n",
            "| Epoch: 49 | Train Loss: 0.315 | Train Acc: 85.16% | Val. Loss: 0.326 | Val. Acc: 85.50% | Time: 799.4989s |\n",
            "| Epoch: 50 | Train Loss: 0.312 | Train Acc: 85.27% | Val. Loss: 0.317 | Val. Acc: 85.44% | Time: 815.9079s |\n",
            "| Epoch: 51 | Train Loss: 0.311 | Train Acc: 85.24% | Val. Loss: 0.339 | Val. Acc: 85.29% | Time: 787.9040s |\n",
            "| Epoch: 52 | Train Loss: 0.310 | Train Acc: 85.39% | Val. Loss: 0.328 | Val. Acc: 85.42% | Time: 774.0384s |\n",
            "| Epoch: 53 | Train Loss: 0.306 | Train Acc: 85.57% | Val. Loss: 0.329 | Val. Acc: 85.54% | Time: 771.3290s |\n",
            "| Epoch: 54 | Train Loss: 0.306 | Train Acc: 85.65% | Val. Loss: 0.324 | Val. Acc: 85.38% | Time: 774.8373s |\n",
            "| Epoch: 55 | Train Loss: 0.304 | Train Acc: 85.85% | Val. Loss: 0.333 | Val. Acc: 85.58% | Time: 803.1091s |\n",
            "| Epoch: 56 | Train Loss: 0.304 | Train Acc: 85.61% | Val. Loss: 0.326 | Val. Acc: 85.85% | Time: 855.5688s |\n",
            "| Epoch: 57 | Train Loss: 0.303 | Train Acc: 85.70% | Val. Loss: 0.325 | Val. Acc: 85.52% | Time: 793.7806s |\n",
            "| Epoch: 58 | Train Loss: 0.300 | Train Acc: 85.92% | Val. Loss: 0.337 | Val. Acc: 85.15% | Time: 825.6335s |\n",
            "| Epoch: 59 | Train Loss: 0.298 | Train Acc: 86.11% | Val. Loss: 0.338 | Val. Acc: 85.43% | Time: 792.7192s |\n",
            "| Epoch: 60 | Train Loss: 0.297 | Train Acc: 86.15% | Val. Loss: 0.337 | Val. Acc: 85.15% | Time: 813.0259s |\n",
            "| Epoch: 61 | Train Loss: 0.298 | Train Acc: 86.00% | Val. Loss: 0.335 | Val. Acc: 85.96% | Time: 809.2810s |\n",
            "| Epoch: 62 | Train Loss: 0.297 | Train Acc: 86.09% | Val. Loss: 0.343 | Val. Acc: 85.26% | Time: 818.4620s |\n",
            "| Epoch: 63 | Train Loss: 0.295 | Train Acc: 86.16% | Val. Loss: 0.363 | Val. Acc: 85.16% | Time: 810.9144s |\n",
            "| Epoch: 64 | Train Loss: 0.293 | Train Acc: 86.32% | Val. Loss: 0.355 | Val. Acc: 85.22% | Time: 827.2395s |\n",
            "| Epoch: 65 | Train Loss: 0.292 | Train Acc: 86.46% | Val. Loss: 0.332 | Val. Acc: 86.01% | Time: 888.8226s |\n",
            "| Epoch: 66 | Train Loss: 0.292 | Train Acc: 86.47% | Val. Loss: 0.351 | Val. Acc: 85.86% | Time: 884.4601s |\n",
            "| Epoch: 67 | Train Loss: 0.289 | Train Acc: 86.54% | Val. Loss: 0.335 | Val. Acc: 85.97% | Time: 875.2619s |\n",
            "| Epoch: 68 | Train Loss: 0.289 | Train Acc: 86.43% | Val. Loss: 0.341 | Val. Acc: 85.57% | Time: 881.9728s |\n",
            "| Epoch: 69 | Train Loss: 0.286 | Train Acc: 86.75% | Val. Loss: 0.324 | Val. Acc: 86.24% | Time: 885.9008s |\n",
            "| Epoch: 70 | Train Loss: 0.286 | Train Acc: 86.45% | Val. Loss: 0.323 | Val. Acc: 85.72% | Time: 881.7977s |\n",
            "| Epoch: 71 | Train Loss: 0.285 | Train Acc: 86.68% | Val. Loss: 0.339 | Val. Acc: 85.96% | Time: 886.2950s |\n",
            "| Epoch: 72 | Train Loss: 0.284 | Train Acc: 86.62% | Val. Loss: 0.345 | Val. Acc: 85.54% | Time: 886.8441s |\n",
            "| Epoch: 73 | Train Loss: 0.282 | Train Acc: 86.95% | Val. Loss: 0.358 | Val. Acc: 84.95% | Time: 881.3831s |\n",
            "| Epoch: 74 | Train Loss: 0.279 | Train Acc: 87.01% | Val. Loss: 0.340 | Val. Acc: 86.08% | Time: 890.8405s |\n",
            "| Epoch: 75 | Train Loss: 0.280 | Train Acc: 86.93% | Val. Loss: 0.357 | Val. Acc: 85.48% | Time: 842.3471s |\n",
            "| Epoch: 76 | Train Loss: 0.281 | Train Acc: 86.90% | Val. Loss: 0.339 | Val. Acc: 85.96% | Time: 831.0151s |\n",
            "| Epoch: 77 | Train Loss: 0.278 | Train Acc: 87.05% | Val. Loss: 0.341 | Val. Acc: 85.77% | Time: 878.2416s |\n",
            "| Epoch: 78 | Train Loss: 0.276 | Train Acc: 87.16% | Val. Loss: 0.355 | Val. Acc: 85.60% | Time: 869.6712s |\n",
            "| Epoch: 79 | Train Loss: 0.276 | Train Acc: 87.12% | Val. Loss: 0.334 | Val. Acc: 85.96% | Time: 789.9679s |\n",
            "| Epoch: 80 | Train Loss: 0.276 | Train Acc: 87.23% | Val. Loss: 0.347 | Val. Acc: 85.74% | Time: 787.0960s |\n",
            "| Epoch: 81 | Train Loss: 0.275 | Train Acc: 87.28% | Val. Loss: 0.359 | Val. Acc: 85.44% | Time: 791.0277s |\n",
            "| Epoch: 82 | Train Loss: 0.274 | Train Acc: 87.42% | Val. Loss: 0.340 | Val. Acc: 85.87% | Time: 849.3630s |\n",
            "| Epoch: 83 | Train Loss: 0.268 | Train Acc: 87.60% | Val. Loss: 0.338 | Val. Acc: 85.74% | Time: 860.3664s |\n",
            "| Epoch: 84 | Train Loss: 0.267 | Train Acc: 87.76% | Val. Loss: 0.358 | Val. Acc: 85.76% | Time: 888.5947s |\n",
            "| Epoch: 85 | Train Loss: 0.268 | Train Acc: 87.60% | Val. Loss: 0.341 | Val. Acc: 85.29% | Time: 898.0496s |\n",
            "| Epoch: 86 | Train Loss: 0.268 | Train Acc: 87.66% | Val. Loss: 0.360 | Val. Acc: 85.05% | Time: 851.5225s |\n",
            "| Epoch: 87 | Train Loss: 0.266 | Train Acc: 87.81% | Val. Loss: 0.343 | Val. Acc: 86.07% | Time: 778.1765s |\n",
            "| Epoch: 88 | Train Loss: 0.263 | Train Acc: 87.84% | Val. Loss: 0.354 | Val. Acc: 85.74% | Time: 781.2973s |\n",
            "| Epoch: 89 | Train Loss: 0.265 | Train Acc: 87.81% | Val. Loss: 0.359 | Val. Acc: 85.46% | Time: 775.1627s |\n",
            "| Epoch: 90 | Train Loss: 0.264 | Train Acc: 87.97% | Val. Loss: 0.380 | Val. Acc: 85.37% | Time: 773.6824s |\n",
            "| Epoch: 91 | Train Loss: 0.263 | Train Acc: 87.95% | Val. Loss: 0.381 | Val. Acc: 85.01% | Time: 826.7961s |\n",
            "| Epoch: 92 | Train Loss: 0.264 | Train Acc: 87.90% | Val. Loss: 0.344 | Val. Acc: 86.13% | Time: 837.5282s |\n",
            "| Epoch: 93 | Train Loss: 0.262 | Train Acc: 88.02% | Val. Loss: 0.361 | Val. Acc: 85.75% | Time: 888.0336s |\n",
            "| Epoch: 94 | Train Loss: 0.259 | Train Acc: 88.16% | Val. Loss: 0.366 | Val. Acc: 85.15% | Time: 889.5769s |\n",
            "| Epoch: 95 | Train Loss: 0.261 | Train Acc: 87.99% | Val. Loss: 0.365 | Val. Acc: 85.38% | Time: 891.6326s |\n",
            "| Epoch: 96 | Train Loss: 0.258 | Train Acc: 88.20% | Val. Loss: 0.382 | Val. Acc: 85.57% | Time: 894.3834s |\n",
            "| Epoch: 97 | Train Loss: 0.258 | Train Acc: 88.19% | Val. Loss: 0.379 | Val. Acc: 85.76% | Time: 896.3308s |\n",
            "| Epoch: 98 | Train Loss: 0.254 | Train Acc: 88.50% | Val. Loss: 0.365 | Val. Acc: 86.00% | Time: 891.3028s |\n",
            "| Epoch: 99 | Train Loss: 0.256 | Train Acc: 88.33% | Val. Loss: 0.359 | Val. Acc: 85.90% | Time: 889.8620s |\n",
            "| Epoch: 100 | Train Loss: 0.253 | Train Acc: 88.49% | Val. Loss: 0.367 | Val. Acc: 85.55% | Time: 888.8671s |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h21vHPpQtoVt",
        "outputId": "28a3307a-ab1e-45a8-feca-5c00de273d86"
      },
      "source": [
        "valid_data = datasets.ImageFolder('fairfaceretinex/Validation', test_transforms)\n",
        "\n",
        "\n",
        "valid_iterator = torch.utils.data.DataLoader(valid_data, batch_size=BATCH_SIZE)\n",
        "model.load_state_dict(torch.load('models/RaceMultiscaleretinex-ResentFT-males-vs-females.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, device, valid_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:05.2f}% |')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 0.316 | Test Acc: 85.34% |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKVTTj4VFgKS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history = np.array(history)\n",
        "plt.plot(history[:,0:2])\n",
        "plt.legend(['Tr Loss', 'Val Loss'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0,10)\n",
        "plt.savefig('loss_curve.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-oJnGeHFjUS"
      },
      "source": [
        "plt.plot(history[:,2:4])\n",
        "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0,1)\n",
        "plt.savefig('accuracy_curve.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwoBJheaFl4K"
      },
      "source": [
        "print(optimizer.state_dict())\n",
        "\n",
        "f = open( 'test_optimizer_state_dict.txt', 'w' )\n",
        "f.write( 'test_optimizer_state_dict = ' + repr(optimizer.state_dict()) + '\\n' )\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S1U5MCgFmi_"
      },
      "source": [
        "#print(model.state_dict())\n",
        "\n",
        "f = open( 'test_model_state_dict.txt', 'w' )\n",
        "f.write( 'test_model_state_dict = ' + repr(model.state_dict()) + '\\n' )\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTRFCNPmFoiT"
      },
      "source": [
        "dict = {'one': 1, 'two': 2}\n",
        "f = open( 'test123.txt', 'w' )\n",
        "f.write( 'dict = ' + repr(dict) + '\\n' )\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC3Ul4BxFqkw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f82fea05-4364-4345-de01-6093b3968cf2"
      },
      "source": [
        "print(history[:,3:4])\n",
        "flat_list = [item for sublist in history[:,3:4] for item in sublist]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.84419118]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRoLpnGaFut2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f22129-dead-471b-9e27-658af0f9f5cb"
      },
      "source": [
        "best_acc=max(flat_list)\n",
        "print(best_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8441911764004651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQV9iwn0Fw3Y"
      },
      "source": [
        "#trial1 = torch.load('epoch_60.pt')\n",
        "#print(trial1)\n",
        "#print(model)\n",
        "import shutil\n",
        "def save_checkpoint123(state123, is_best123, filename123='checkpoint.pth.tar'):\n",
        "    torch.save(state123, filename123)\n",
        "    if is_best123:\n",
        "        shutil.copyfile(filename123, 'model_best.pth.tar')\n",
        "        \n",
        "save_checkpoint123({\n",
        "            'epoch': epoch + 1,\n",
        "            'arch': 'resnet18',\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_prec1': best_acc,\n",
        "            'optimizer' : optimizer.state_dict(),\n",
        "            'all_history': history,\n",
        "            'exp_lr_scheduler_dict' : exp_lr_scheduler.state_dict(),\n",
        "        }, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKvzIn_NFzm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ecebf74-71f0-4144-c0af-d407227355fb"
      },
      "source": [
        "resume = 'model_best.pth.tar'\n",
        "if resume:\n",
        "        if os.path.isfile(resume):\n",
        "            print(\"=> loading checkpoint '{}'\".format(resume))\n",
        "            checkpoint = torch.load(resume)\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            best_prec1 = checkpoint['best_prec1']\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "            all_history = (checkpoint['all_history']).tolist()\n",
        "            exp_lr_scheduler = checkpoint['exp_lr_scheduler_dict']\n",
        "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "                  .format(resume, checkpoint['epoch']))\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(args.resume))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loading checkpoint 'model_best.pth.tar'\n",
            "=> loaded checkpoint 'model_best.pth.tar' (epoch 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d6_VOTJF11b"
      },
      "source": [
        "print(start_epoch)\n",
        "print(all_history)\n",
        "history = all_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVe10vHRF35Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11904254-901f-477c-86df-ad0ed6e05018"
      },
      "source": [
        "EPOCHS = 4\n",
        "SAVE_DIR = 'models'\n",
        "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'EpochIncrementRaceresnet-ResentFT-males-vs-females.pt')\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "if not os.path.isdir(f'{SAVE_DIR}'):\n",
        "    os.makedirs(f'{SAVE_DIR}')\n",
        "history = []\n",
        "for epoch in range(start_epoch,start_epoch+EPOCHS):\n",
        "    epoch_start = time.time()\n",
        "    train_loss, train_acc = train(model, device, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, device, valid_iterator, criterion)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "    \n",
        "    history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
        "    epoch_end = time.time()\n",
        "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:05.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:05.2f}% | Time: {epoch_end-epoch_start:.4f}s |')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.345 | Train Acc: 83.44% | Val. Loss: 0.332 | Val. Acc: 84.42% | Time: 1045.6672s |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4ZnWhOnF9kh"
      },
      "source": [
        "model.load_state_dict(torch.load('models/EpochIncrementRaceresnet-ResentFT-males-vs-females.pt'))\n",
        "test_data = datasets.ImageFolder(dataset+'\\\\validation', test_transforms)\n",
        "class_names = test_data.classes\n",
        "\n",
        "dataloaders = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)\n",
        "nb_classes = 460\n",
        "\n",
        "\n",
        "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "print(confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BktM08BhF_5p"
      },
      "source": [
        "print(confusion_matrix)\n",
        "print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
        "Ind_acc = confusion_matrix.diag()/confusion_matrix.sum(1)\n",
        "print(\"Female : \", float(Ind_acc[0]))s\n",
        "print(\"Male : \", float(Ind_acc[1]))\n",
        "TN = int(confusion_matrix[0][0])\n",
        "FN = int(confusion_matrix[0][1])\n",
        "FP = int(confusion_matrix[1][0])\n",
        "TP = int(confusion_matrix[1][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMtc08EcGAa2"
      },
      "source": [
        "FPR = 0\n",
        "FNR = 0\n",
        "TPR = 0\n",
        "TNR = 0\n",
        "FPR = FP/(FP + TN)\n",
        "FNR = FN/(FN + TP)\n",
        "TPR = 1 - FNR\n",
        "TNR = 1 - FPR\n",
        "Overall_acc = (TPR + TNR)/2\n",
        "print(\"Overall Accuracy : \", Overall_acc)\n",
        "print(\"Female : \", float(Ind_acc[0]))\n",
        "print(\"Male : \", float(Ind_acc[1]))\n",
        "print(\"FPR : \", FNR)\n",
        "print(\"FNR : \", FPR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO_jRBOOGCbe"
      },
      "source": [
        "   model.eval()\n",
        "    num_correct = 0 \n",
        "    num_examples = 0\n",
        "    for batch in val_loader:\n",
        "        inputs, targets = batch\n",
        "        inputs = inputs.to(device)\n",
        "        output = model(inputs)\n",
        "        targets = targets.to(device)\n",
        "        loss = loss_fn(output,targets) \n",
        "        valid_loss += loss.data.item() * inputs.size(0)\n",
        "        correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n",
        "        num_correct += torch.sum(correct).item()\n",
        "        num_examples += correct.shape[0]\n",
        "    valid_loss /= len(val_loader.dataset)\n",
        " \n",
        "    print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n",
        "    valid_loss, num_correct / num_examples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzLAwiKnGFrN"
      },
      "source": [
        "summary(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr-0EQz5AZ9g"
      },
      "source": [
        "end of epoch increment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a2EDFfRAU4S"
      },
      "source": [
        "#val = r'../pradeep/Desktop/FinalRacedataets/RaceEqu/Validation/'\n",
        "val = 'Raceretinex/Validation'\n",
        "races = os.listdir(val)\n",
        "genders = ['Male','Female']\n",
        "for race in races:\n",
        "    for gender in genders:\n",
        "        finalPath = val+race+'/'+gender\n",
        "        #print(finalPath)\n",
        "\n",
        "\n",
        "        test_data = datasets.ImageFolder(finalPath, test_transforms)\n",
        "\n",
        "\n",
        "        test_iterator = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)\n",
        "        model.load_state_dict(torch.load('models/ResentFT-males-vs-females.pt'))\n",
        "\n",
        "        test_loss, test_acc = evaluate(model, device, test_iterator, criterion)\n",
        "\n",
        "        print(f'{race} {gender}| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:05.2f}% |')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyTktxV1pOqO"
      },
      "source": [
        "data_transforms = {\n",
        "    'test': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = 'dataset'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['test', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['6-10', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['6-10', 'val']}\n",
        "class_names = image_datasets['val'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7LNJhvJpOqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "910eca3f-8335-4738-ae3c-7452871f3e01"
      },
      "source": [
        "model.load_state_dict(torch.load('models/ResentFT-males-vs-females.pt'))\n",
        "test_data = datasets.ImageFolder('fairfaceretinex/Validation', test_transforms)\n",
        "class_names = test_data.classes\n",
        "\n",
        "dataloaders = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)\n",
        "nb_classes = 2\n",
        "\n",
        "\n",
        "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "print(confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4559.,  545.],\n",
            "        [ 568., 5164.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai_Zk2K1pOqT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e21010-cdb4-49dd-b582-2aa1a2c96487"
      },
      "source": [
        "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.8932, 0.9009])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt3lhBrspOqV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDEaEatGpOqY"
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zA51gmxpOqb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "plt.ion() \n",
        "\n",
        "def visualize_model(model, num_images=22):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "           # print('GroundTruth: ', ' '.join('%5s' % class_names[labels[j]] for j in range(22)))\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                print('GroudthTruth: ',class_names[labels[j]])\n",
        "                ax.set_title('Predicted: {}'.format(class_names[preds[j]]))\n",
        "               \n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0W5HUwCpOql"
      },
      "source": [
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "visualize_model(model)\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}